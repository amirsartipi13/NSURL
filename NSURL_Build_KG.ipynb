{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSURL-Build-KG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53cb5d96bf7f4e2cbee550d70fb08df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d0f495092a34ef18816d706dd307fc5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d14fb58883f1496c9ec1db21e77412d1",
              "IPY_MODEL_4c7878e984734bc993e7883139534ce0"
            ]
          }
        },
        "5d0f495092a34ef18816d706dd307fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d14fb58883f1496c9ec1db21e77412d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c763d37d7f4540dba3e307dd24aa1a7b",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61a1c5d09513408da625b24caa21a7dd"
          }
        },
        "4c7878e984734bc993e7883139534ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f8ae7ee015d4b4f88e95f14e333f37d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/5 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4795c44414a1435fac411f016716021f"
          }
        },
        "c763d37d7f4540dba3e307dd24aa1a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61a1c5d09513408da625b24caa21a7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f8ae7ee015d4b4f88e95f14e333f37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4795c44414a1435fac411f016716021f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3dbc70e46ad44c08be5492d8c08d3a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7a8eaad41f74fca931613255268f085",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_353add6811274358a1c9e0bdee231bc4",
              "IPY_MODEL_fd24ad495bd14cbf97aa7daca33d5c65"
            ]
          }
        },
        "e7a8eaad41f74fca931613255268f085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "353add6811274358a1c9e0bdee231bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d72f41ccc57e4b39833538a51247e72a",
            "_dom_classes": [],
            "description": "Epoch 1:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 507,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d26a3ea41da45e79a25edea5f918aa4"
          }
        },
        "fd24ad495bd14cbf97aa7daca33d5c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d76fdb728b0c40eb96e1cd978fe43505",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/507 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae01f76de5e3408e97b2e8eae0a6a848"
          }
        },
        "d72f41ccc57e4b39833538a51247e72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d26a3ea41da45e79a25edea5f918aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d76fdb728b0c40eb96e1cd978fe43505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae01f76de5e3408e97b2e8eae0a6a848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirsartipi13/NSURL/blob/main/NSURL_Build_KG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sWpKhfCbR3C",
        "outputId": "3b4e6e13-bc1e-4e3a-e40a-324f0c2e757e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYIO_uq7c8le"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeLw6vypZRLR"
      },
      "source": [
        "train_path = './drive/MyDrive/data_sets/PERLEX/train.txt'\n",
        "test_path = './drive/MyDrive/data_sets/PERLEX/test.txt'\n",
        "\n",
        "# train_path = './drive/MyDrive/dataset/perlex/train.txt'\n",
        "# test_path = './drive/MyDrive/dataset/perlex/test.txt'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoZZEdCNi1pk"
      },
      "source": [
        "def get_e1(text):\n",
        "  text = re.sub('<e2>', '', text)\n",
        "  text = re.sub('</e2>', '', text)\n",
        "  e = re.findall(\"<e1>(.*?)</e1>\", text)\n",
        "  pre_process = set()\n",
        "  for ent in e:\n",
        "    if ent != ' ' and len(ent.strip())>1:\n",
        "      pre_process.add(ent.strip())\n",
        "  return pre_process"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5QNaaQvuFGE"
      },
      "source": [
        "def get_e2(text):\n",
        "  text = re.sub('<e1>', '', text)\n",
        "  text = re.sub('</e1>', '', text)\n",
        "  e = re.findall(\"<e2>(.*?)</e2>\", text)\n",
        "  pre_process = set()\n",
        "  for ent in e:\n",
        "    if ent != ' ' and len(ent.strip())>1:\n",
        "      pre_process.add(ent.strip())\n",
        "  return pre_process"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e-jMawXKWy5"
      },
      "source": [
        "SEMEVAL_RELATION_LABELS = ['Other', 'Message-Topic(e1,e2)', 'Message-Topic(e2,e1)',\n",
        "                   'Product-Producer(e1,e2)', 'Product-Producer(e2,e1)',\n",
        "                   'Instrument-Agency(e1,e2)', 'Instrument-Agency(e2,e1)',\n",
        "                   'Entity-Destination(e1,e2)', 'Entity-Destination(e2,e1)',\n",
        "                   'Cause-Effect(e1,e2)', 'Cause-Effect(e2,e1)',\n",
        "                   'Component-Whole(e1,e2)', 'Component-Whole(e2,e1)',\n",
        "                   'Entity-Origin(e1,e2)', 'Entity-Origin(e2,e1)',\n",
        "                   'Member-Collection(e1,e2)', 'Member-Collection(e2,e1)',\n",
        "                   'Content-Container(e1,e2)', 'Content-Container(e2,e1)']"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7puIrckKZ_p",
        "outputId": "1f4721fd-f7d3-4577-bfb9-b9b04e8e6b15"
      },
      "source": [
        "indx2label = dict(enumerate(SEMEVAL_RELATION_LABELS))\n",
        "indx2label"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Other',\n",
              " 1: 'Message-Topic(e1,e2)',\n",
              " 2: 'Message-Topic(e2,e1)',\n",
              " 3: 'Product-Producer(e1,e2)',\n",
              " 4: 'Product-Producer(e2,e1)',\n",
              " 5: 'Instrument-Agency(e1,e2)',\n",
              " 6: 'Instrument-Agency(e2,e1)',\n",
              " 7: 'Entity-Destination(e1,e2)',\n",
              " 8: 'Entity-Destination(e2,e1)',\n",
              " 9: 'Cause-Effect(e1,e2)',\n",
              " 10: 'Cause-Effect(e2,e1)',\n",
              " 11: 'Component-Whole(e1,e2)',\n",
              " 12: 'Component-Whole(e2,e1)',\n",
              " 13: 'Entity-Origin(e1,e2)',\n",
              " 14: 'Entity-Origin(e2,e1)',\n",
              " 15: 'Member-Collection(e1,e2)',\n",
              " 16: 'Member-Collection(e2,e1)',\n",
              " 17: 'Content-Container(e1,e2)',\n",
              " 18: 'Content-Container(e2,e1)'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwRmGwpUKbCx",
        "outputId": "bed7ea44-5141-4b61-d7d3-2c987cdd3cd7"
      },
      "source": [
        "label2index = {v:k for k,v in indx2label.items()}\n",
        "label2index"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cause-Effect(e1,e2)': 9,\n",
              " 'Cause-Effect(e2,e1)': 10,\n",
              " 'Component-Whole(e1,e2)': 11,\n",
              " 'Component-Whole(e2,e1)': 12,\n",
              " 'Content-Container(e1,e2)': 17,\n",
              " 'Content-Container(e2,e1)': 18,\n",
              " 'Entity-Destination(e1,e2)': 7,\n",
              " 'Entity-Destination(e2,e1)': 8,\n",
              " 'Entity-Origin(e1,e2)': 13,\n",
              " 'Entity-Origin(e2,e1)': 14,\n",
              " 'Instrument-Agency(e1,e2)': 5,\n",
              " 'Instrument-Agency(e2,e1)': 6,\n",
              " 'Member-Collection(e1,e2)': 15,\n",
              " 'Member-Collection(e2,e1)': 16,\n",
              " 'Message-Topic(e1,e2)': 1,\n",
              " 'Message-Topic(e2,e1)': 2,\n",
              " 'Other': 0,\n",
              " 'Product-Producer(e1,e2)': 3,\n",
              " 'Product-Producer(e2,e1)': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90806UPAKnE6",
        "outputId": "020a1d3b-4b00-445b-e605-98a84a561163"
      },
      "source": [
        "label2index['Other']"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w6PxdVabeu8"
      },
      "source": [
        "def label_spliter(label):\n",
        "  # component-whole(e2,e1)\n",
        "  # return [whole , component ]\n",
        "  order = re.findall(\"\\((.*?)\\)\", label)[0].split(',')\n",
        "  label_names = label.split(\"(\")[0].split(\"-\")\n",
        "  if order[0] == \"e1\":\n",
        "    return label_names\n",
        "  else:\n",
        "    return list(reversed(label_names))\n",
        "\n",
        "def make_dataframe_row(sentence,label):\n",
        "  \n",
        "  if label == \"Other\":\n",
        "    labels =[label, label]\n",
        "  else:\n",
        "    labels = label_spliter(label=label)\n",
        "\n",
        "  result = []\n",
        "  e1s = get_e1(sentence)  \n",
        "  e2s = get_e2(sentence)\n",
        "  for e1 in e1s:\n",
        "    for e2 in e2s:\n",
        "\n",
        "      result.append( {\n",
        "          \"e1\":e1,\n",
        "          \"e2\":e2,\n",
        "          \"e1_label\":labels[0],\n",
        "          \"e2_label\":labels[1],\n",
        "          \"label\":label,\n",
        "          \"nlabel\": label2index[label],\n",
        "          \"sentence\":sentence\n",
        "      })\n",
        "\n",
        "  return result\n",
        "    \n",
        "def make_dataframe(path):\n",
        "    f = open(path, 'r')\n",
        "    data = [x.rstrip() for x in f] \n",
        "    data_set_rows = []\n",
        "    for i in range(0, len(data)-4, 4):\n",
        "      item = data[i].split('\\t')\n",
        "      sentence = re.sub('[!@#$،.]', '', item[1])\n",
        "\n",
        "      label = data[i+1]\n",
        "      rows = make_dataframe_row(sentence , label)\n",
        "      data_set_rows += rows\n",
        "\n",
        "    return pd.DataFrame(data_set_rows)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "quBnj4Zfh6UR",
        "outputId": "b237fcbd-6d96-49a1-f828-27b72f9114c9"
      },
      "source": [
        "df = make_dataframe(train_path)\n",
        "df_test = make_dataframe(test_path)\n",
        "df_test"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>e1</th>\n",
              "      <th>e2</th>\n",
              "      <th>e1_label</th>\n",
              "      <th>e2_label</th>\n",
              "      <th>label</th>\n",
              "      <th>nlabel</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>حسابرسی‌ها</td>\n",
              "      <td>ضایعات</td>\n",
              "      <td>Message</td>\n",
              "      <td>Topic</td>\n",
              "      <td>Message-Topic(e1,e2)</td>\n",
              "      <td>1</td>\n",
              "      <td>\"معمول ترین &lt;e1&gt;حسابرسی‌ها &lt;/e1&gt;مربوط به &lt;e2&gt;ض...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>شرکت</td>\n",
              "      <td>صندلی‌های</td>\n",
              "      <td>Producer</td>\n",
              "      <td>Product</td>\n",
              "      <td>Product-Producer(e2,e1)</td>\n",
              "      <td>4</td>\n",
              "      <td>\"این &lt;e1&gt;شرکت &lt;e2&gt;&lt;/e1&gt;صندلی‌های &lt;/e2&gt;پلاستیکی...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>استاد</td>\n",
              "      <td>چوب</td>\n",
              "      <td>Agency</td>\n",
              "      <td>Instrument</td>\n",
              "      <td>Instrument-Agency(e2,e1)</td>\n",
              "      <td>6</td>\n",
              "      <td>\"&lt;e1&gt;استاد &lt;/e1&gt;مدرسه با یک &lt;e2&gt;چوب &lt;/e2&gt;درس م...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>بدن</td>\n",
              "      <td>آب‌انبار</td>\n",
              "      <td>Entity</td>\n",
              "      <td>Destination</td>\n",
              "      <td>Entity-Destination(e1,e2)</td>\n",
              "      <td>7</td>\n",
              "      <td>\"مظنون &lt;e1&gt;بدن &lt;/e1&gt;مرده را به یک &lt;e2&gt;آب‌انبار...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>آنفولانزای</td>\n",
              "      <td>ویروس</td>\n",
              "      <td>Effect</td>\n",
              "      <td>Cause</td>\n",
              "      <td>Cause-Effect(e2,e1)</td>\n",
              "      <td>10</td>\n",
              "      <td>\"&lt;e1&gt;آنفولانزای &lt;/e1&gt;مرغی یک بیماری عفونی پرند...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2745</th>\n",
              "      <td>بقایای</td>\n",
              "      <td>طوفان</td>\n",
              "      <td>Entity</td>\n",
              "      <td>Origin</td>\n",
              "      <td>Entity-Origin(e1,e2)</td>\n",
              "      <td>13</td>\n",
              "      <td>\"هوا دیروز بادی و سرد بود و هنوز &lt;e1&gt;بقایای &lt;/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2746</th>\n",
              "      <td>پادشاه</td>\n",
              "      <td>جارو می کشد</td>\n",
              "      <td>Agency</td>\n",
              "      <td>Instrument</td>\n",
              "      <td>Instrument-Agency(e2,e1)</td>\n",
              "      <td>6</td>\n",
              "      <td>\"پس از جاگذاری تمام بتها  که خود ساعت‌ها طول م...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2747</th>\n",
              "      <td>مصالح</td>\n",
              "      <td>صنایع</td>\n",
              "      <td>Product</td>\n",
              "      <td>Producer</td>\n",
              "      <td>Product-Producer(e1,e2)</td>\n",
              "      <td>3</td>\n",
              "      <td>\"وزیر تولید کندِ &lt;e1&gt;مصالح &lt;/e1&gt;توسط &lt;e2&gt;صنایع...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2748</th>\n",
              "      <td>چتر</td>\n",
              "      <td>قاب</td>\n",
              "      <td>Whole</td>\n",
              "      <td>Component</td>\n",
              "      <td>Component-Whole(e2,e1)</td>\n",
              "      <td>12</td>\n",
              "      <td>\"&lt;e2&gt;قاب &lt;e1&gt;&lt;/e2&gt;چتر &lt;/e1&gt;دارای یك گیره متحرك...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2749</th>\n",
              "      <td>فیلم</td>\n",
              "      <td>فروشنده</td>\n",
              "      <td>Product</td>\n",
              "      <td>Producer</td>\n",
              "      <td>Product-Producer(e1,e2)</td>\n",
              "      <td>3</td>\n",
              "      <td>\"(کف دست : دست‌های چاق ) یک &lt;e1&gt;فیلم &lt;/e1&gt;ترسن...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2750 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              e1  ...                                           sentence\n",
              "0     حسابرسی‌ها  ...  \"معمول ترین <e1>حسابرسی‌ها </e1>مربوط به <e2>ض...\n",
              "1           شرکت  ...  \"این <e1>شرکت <e2></e1>صندلی‌های </e2>پلاستیکی...\n",
              "2          استاد  ...  \"<e1>استاد </e1>مدرسه با یک <e2>چوب </e2>درس م...\n",
              "3            بدن  ...  \"مظنون <e1>بدن </e1>مرده را به یک <e2>آب‌انبار...\n",
              "4     آنفولانزای  ...  \"<e1>آنفولانزای </e1>مرغی یک بیماری عفونی پرند...\n",
              "...          ...  ...                                                ...\n",
              "2745      بقایای  ...  \"هوا دیروز بادی و سرد بود و هنوز <e1>بقایای </...\n",
              "2746      پادشاه  ...  \"پس از جاگذاری تمام بتها  که خود ساعت‌ها طول م...\n",
              "2747       مصالح  ...  \"وزیر تولید کندِ <e1>مصالح </e1>توسط <e2>صنایع...\n",
              "2748         چتر  ...  \"<e2>قاب <e1></e2>چتر </e1>دارای یك گیره متحرك...\n",
              "2749        فیلم  ...  \"(کف دست : دست‌های چاق ) یک <e1>فیلم </e1>ترسن...\n",
              "\n",
              "[2750 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWf9tpdMK3Q9",
        "outputId": "ea83830d-c2f0-4de4-8716-2d896abb08d4"
      },
      "source": [
        "possible_labels = df.nlabel.unique()\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1,\n",
              " 1: 7,\n",
              " 2: 13,\n",
              " 3: 14,\n",
              " 4: 8,\n",
              " 5: 17,\n",
              " 6: 2,\n",
              " 7: 5,\n",
              " 8: 18,\n",
              " 9: 11,\n",
              " 10: 4,\n",
              " 11: 12,\n",
              " 12: 0,\n",
              " 13: 10,\n",
              " 14: 15,\n",
              " 15: 3,\n",
              " 16: 9,\n",
              " 17: 6,\n",
              " 18: 16}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJVgYiTQ4oWy"
      },
      "source": [
        "# Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEVF0cCI5L1h"
      },
      "source": [
        "X_train = df.sentence.tolist()\n",
        "X_val =  df_test.sentence.tolist()\n",
        "y_train = df.nlabel.tolist()\n",
        "y_val =  df_test.nlabel.tolist()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zofSzmcoxe5",
        "outputId": "d23b8aec-e959-47cf-9241-d99f446342f1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpfeWKk9o0Zg"
      },
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHb6rnmRo_Hl",
        "outputId": "5bcb8910-57c6-47f9-993b-729e92b0e337"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")  \n",
        "device"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwaChGIho2ke",
        "outputId": "17097413-f4f1-46a9-b046-40999c42999c"
      },
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        "# model_name = 'xlm-roberta-base'\n",
        "# model_name = 'HooshvareLab/bert-fa-zwnj-base'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model  = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2index))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp0r1YJAPTf4"
      },
      "source": [
        "# device = torch.device('cpu')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "3q08jJrvpEft",
        "outputId": "4b96e0cd-ab96-496e-989e-5c771b89388e"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-7750c7ee2c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eunJ4jiopJZN",
        "outputId": "4e800fe7-119d-42f5-c4c2-5b3fad2c2656"
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    X_train, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nETBNjxrpN0o",
        "outputId": "670b644e-4634-4006-8e95-c5cb3ec28542"
      },
      "source": [
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    X_val, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=256, \n",
        "    return_tensors='pt'\n",
        ")\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7faEA7QpR9E"
      },
      "source": [
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(y_train)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(y_val)\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s1ILoBapU0f"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 16\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "dataloader_validation = DataLoader(dataset_val, \n",
        "                                   sampler=SequentialSampler(dataset_val), \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxygMCLZpXPF"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=1e-5, \n",
        "                  eps=1e-8)\n",
        "epochs = 5\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kqsKcLupaqE"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    tt = 0\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(\"Acc with percent:\", len(y_preds[y_preds==label])/len(y_true))\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
        "        tt += len(y_preds[y_preds==label])/len(y_true)\n",
        "    return tt\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "53cb5d96bf7f4e2cbee550d70fb08df2",
            "5d0f495092a34ef18816d706dd307fc5",
            "d14fb58883f1496c9ec1db21e77412d1",
            "4c7878e984734bc993e7883139534ce0",
            "c763d37d7f4540dba3e307dd24aa1a7b",
            "61a1c5d09513408da625b24caa21a7dd",
            "9f8ae7ee015d4b4f88e95f14e333f37d",
            "4795c44414a1435fac411f016716021f",
            "3dbc70e46ad44c08be5492d8c08d3a23",
            "e7a8eaad41f74fca931613255268f085",
            "353add6811274358a1c9e0bdee231bc4",
            "fd24ad495bd14cbf97aa7daca33d5c65",
            "d72f41ccc57e4b39833538a51247e72a",
            "1d26a3ea41da45e79a25edea5f918aa4",
            "d76fdb728b0c40eb96e1cd978fe43505",
            "ae01f76de5e3408e97b2e8eae0a6a848"
          ]
        },
        "id": "F7gIgUsvrgf3",
        "outputId": "7bcd19dd-ee53-4651-e7c7-dacdd9789e78"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "training_stats = []\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals\n",
        "    \n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }  \n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    # torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "\n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tt_accuracy = accuracy_per_class(predictions, true_vals)\n",
        "    \n",
        "    tqdm.write(f'accuracy: {tt_accuracy}')\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch,\n",
        "            'Training Loss': loss_train_avg,\n",
        "            'Valid. Loss': val_loss,\n",
        "            'Valid. Accur.': tt_accuracy/3\n",
        "        }\n",
        "    )\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53cb5d96bf7f4e2cbee550d70fb08df2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dbc70e46ad44c08be5492d8c08d3a23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=507.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-9294a5c53bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         inputs = {'input_ids':      batch[0],\n",
            "\u001b[0;32m<ipython-input-57-9294a5c53bab>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         inputs = {'input_ids':      batch[0],\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4OAbeNhrlMQ"
      },
      "source": [
        "torch.save(model.state_dict(), f'/content/drive/MyDrive/finetuned_HooshvareLab_epoch_{epoch}.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KyoJjujrnLO"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats[]\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR-1MYjSgK0i"
      },
      "source": [
        "# R-BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnjmGbrnpkWj",
        "outputId": "c46159b2-b195-475d-8092-c8fea7d4bea0"
      },
      "source": [
        "! git clone https://github.com/mickeystroller/R-BERT.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'R-BERT' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV-NtUsXps0f"
      },
      "source": [
        "! cp -a ./R-BERT/* ./\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D9K1btYe5UA"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONtbFRnbMSm"
      },
      "source": [
        "# import utils\n",
        "import r_bert"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3hWoE0TbWEi",
        "outputId": "995fb411-8ed2-41e4-98d2-867b3d8f7d91"
      },
      "source": [
        "! CUDA_VISIBLE_DEVICES=0 python r_bert.py --config config.ini\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-05 08:44:30.776047: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "08/05/2021 08:44:32 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n",
            "08/05/2021 08:44:32 - INFO - filelock -   Lock 139799525361232 acquired on /root/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d.lock\n",
            "Downloading: 100% 571/571 [00:00<00:00, 564kB/s]\n",
            "08/05/2021 08:44:32 - INFO - filelock -   Lock 139799525361232 released on /root/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d.lock\n",
            "08/05/2021 08:44:33 - INFO - filelock -   Lock 139799525361360 acquired on /root/.cache/huggingface/transformers/e12f02d630da91a0982ce6db1ad595231d155a2b725ab106971898276d842ecc.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 1.71MB/s]\n",
            "08/05/2021 08:44:33 - INFO - filelock -   Lock 139799525361360 released on /root/.cache/huggingface/transformers/e12f02d630da91a0982ce6db1ad595231d155a2b725ab106971898276d842ecc.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "08/05/2021 08:44:34 - INFO - filelock -   Lock 139799385478864 acquired on /root/.cache/huggingface/transformers/300ecd79785b4602752c0085f8a89c3f0232ef367eda291c79a5600f3778b677.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 25.9kB/s]\n",
            "08/05/2021 08:44:35 - INFO - filelock -   Lock 139799385478864 released on /root/.cache/huggingface/transformers/300ecd79785b4602752c0085f8a89c3f0232ef367eda291c79a5600f3778b677.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
            "08/05/2021 08:44:35 - INFO - filelock -   Lock 139799385478480 acquired on /root/.cache/huggingface/transformers/475d46024228961ca8770cead39e1079f135fd2441d14cf216727ffac8d41d78.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 2.57MB/s]\n",
            "08/05/2021 08:44:35 - INFO - filelock -   Lock 139799385478480 released on /root/.cache/huggingface/transformers/475d46024228961ca8770cead39e1079f135fd2441d14cf216727ffac8d41d78.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "08/05/2021 08:44:36 - INFO - filelock -   Lock 139799376335376 acquired on /root/.cache/huggingface/transformers/1d959166dd7e047e57ea1b2d9b7b9669938a7e90c5e37a03961ad9f15eaea17f.fea64cd906e3766b04c92397f9ad3ff45271749cbe49829a079dd84e34c1697d.lock\n",
            "Downloading: 100% 1.34G/1.34G [00:22<00:00, 60.5MB/s]\n",
            "08/05/2021 08:44:59 - INFO - filelock -   Lock 139799376335376 released on /root/.cache/huggingface/transformers/1d959166dd7e047e57ea1b2d9b7b9669938a7e90c5e37a03961ad9f15eaea17f.fea64cd906e3766b04c92397f9ad3ff45271749cbe49829a079dd84e34c1697d.lock\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "08/05/2021 08:45:15 - INFO - __main__ -   Creating features from dataset file at ./data\n",
            "08/05/2021 08:45:15 - INFO - utils -   LOOKING AT ./data/train.tsv\n",
            "08/05/2021 08:45:15 - INFO - utils -   Writing example 0 of 8000\n",
            "08/05/2021 08:45:15 - INFO - utils -   *** Example ***\n",
            "08/05/2021 08:45:15 - INFO - utils -   guid: train-0\n",
            "08/05/2021 08:45:15 - INFO - utils -   tokens: [CLS] the system as described above has its greatest application in an array ##ed [E11] configuration [E12] of antenna [E21] elements [E22] [SEP]\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_ids: 101 1996 2291 2004 2649 2682 2038 2049 4602 4646 1999 2019 9140 2098 30522 9563 30523 1997 13438 30524 3787 30525 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e11_p: 15\n",
            "08/05/2021 08:45:15 - INFO - utils -   e12_p: 16\n",
            "08/05/2021 08:45:15 - INFO - utils -   e21_p: 20\n",
            "08/05/2021 08:45:15 - INFO - utils -   e22_p: 21\n",
            "08/05/2021 08:45:15 - INFO - utils -   e1_mask: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e2_mask: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   segment_ids: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   label: 12 (id = 12)\n",
            "08/05/2021 08:45:15 - INFO - utils -   *** Example ***\n",
            "08/05/2021 08:45:15 - INFO - utils -   guid: train-1\n",
            "08/05/2021 08:45:15 - INFO - utils -   tokens: [CLS] the [E11] child [E12] was carefully wrapped and bound into the [E21] cradle [E22] by means of a cord [SEP]\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_ids: 101 1996 30522 2775 30523 2001 5362 5058 1998 5391 2046 1996 30524 18293 30525 2011 2965 1997 1037 11601 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e11_p: 3\n",
            "08/05/2021 08:45:15 - INFO - utils -   e12_p: 4\n",
            "08/05/2021 08:45:15 - INFO - utils -   e21_p: 13\n",
            "08/05/2021 08:45:15 - INFO - utils -   e22_p: 14\n",
            "08/05/2021 08:45:15 - INFO - utils -   e1_mask: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e2_mask: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   segment_ids: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   label: 0 (id = 0)\n",
            "08/05/2021 08:45:15 - INFO - utils -   *** Example ***\n",
            "08/05/2021 08:45:15 - INFO - utils -   guid: train-2\n",
            "08/05/2021 08:45:15 - INFO - utils -   tokens: [CLS] the [E11] author [E12] of a key ##gen uses a [E21] di ##sas ##se ##mble ##r [E22] to look at the raw assembly code [SEP]\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_ids: 101 1996 30522 3166 30523 1997 1037 3145 6914 3594 1037 30524 4487 20939 3366 19661 2099 30525 2000 2298 2012 1996 6315 3320 3642 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e11_p: 3\n",
            "08/05/2021 08:45:15 - INFO - utils -   e12_p: 4\n",
            "08/05/2021 08:45:15 - INFO - utils -   e21_p: 12\n",
            "08/05/2021 08:45:15 - INFO - utils -   e22_p: 17\n",
            "08/05/2021 08:45:15 - INFO - utils -   e1_mask: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e2_mask: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   segment_ids: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   label: 6 (id = 6)\n",
            "08/05/2021 08:45:15 - INFO - utils -   *** Example ***\n",
            "08/05/2021 08:45:15 - INFO - utils -   guid: train-3\n",
            "08/05/2021 08:45:15 - INFO - utils -   tokens: [CLS] a misty [E11] ridge [E12] up ##rise ##s from the [E21] surge [E22] [SEP]\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_ids: 101 1037 15167 30522 5526 30523 2039 29346 2015 2013 1996 30524 12058 30525 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e11_p: 4\n",
            "08/05/2021 08:45:15 - INFO - utils -   e12_p: 5\n",
            "08/05/2021 08:45:15 - INFO - utils -   e21_p: 12\n",
            "08/05/2021 08:45:15 - INFO - utils -   e22_p: 13\n",
            "08/05/2021 08:45:15 - INFO - utils -   e1_mask: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e2_mask: 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   segment_ids: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   label: 0 (id = 0)\n",
            "08/05/2021 08:45:15 - INFO - utils -   *** Example ***\n",
            "08/05/2021 08:45:15 - INFO - utils -   guid: train-4\n",
            "08/05/2021 08:45:15 - INFO - utils -   tokens: [CLS] the [E11] student [E12] [E21] association [E22] is the voice of the undergraduate student population of the state university of new york at buffalo [SEP]\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_ids: 101 1996 30522 3076 30523 30524 2523 30525 2003 1996 2376 1997 1996 8324 3076 2313 1997 1996 2110 2118 1997 2047 2259 2012 6901 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e11_p: 3\n",
            "08/05/2021 08:45:15 - INFO - utils -   e12_p: 4\n",
            "08/05/2021 08:45:15 - INFO - utils -   e21_p: 6\n",
            "08/05/2021 08:45:15 - INFO - utils -   e22_p: 7\n",
            "08/05/2021 08:45:15 - INFO - utils -   e1_mask: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   e2_mask: 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   segment_ids: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "08/05/2021 08:45:15 - INFO - utils -   label: 15 (id = 15)\n",
            "08/05/2021 08:45:19 - INFO - __main__ -   Saving features into cached file ./data/cached_train_bert-large-uncased_128_semeval\n",
            "08/05/2021 08:45:21 - INFO - __main__ -   ***** Running training *****\n",
            "08/05/2021 08:45:21 - INFO - __main__ -     Num examples = 8000\n",
            "08/05/2021 08:45:21 - INFO - __main__ -     Num Epochs = 5\n",
            "08/05/2021 08:45:21 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
            "08/05/2021 08:45:21 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "08/05/2021 08:45:21 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "08/05/2021 08:45:21 - INFO - __main__ -     Total optimization steps = 2500\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/500 [00:00<?, ?it/s]\u001b[A/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [105,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:702: indexSelectLargeIndex: block: [90,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "Traceback (most recent call last):\n",
            "  File \"r_bert.py\", line 423, in <module>\n",
            "    main()\n",
            "  File \"r_bert.py\", line 369, in main\n",
            "    global_step, tr_loss = train(config, train_dataset, model, tokenizer)\n",
            "  File \"r_bert.py\", line 124, in train\n",
            "    outputs = model(**inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/model.py\", line 54, in forward\n",
            "    attention_mask=attention_mask, head_mask=head_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 1001, in forward\n",
            "    return_dict=return_dict,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 589, in forward\n",
            "    output_attentions,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 475, in forward\n",
            "    past_key_value=self_attn_past_key_value,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 408, in forward\n",
            "    output_attentions,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\", line 267, in forward\n",
            "    mixed_query_layer = self.query(hidden_states)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 96, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1847, in linear\n",
            "    return torch._C._nn.linear(input, weight, bias)\n",
            "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
            "\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/500 [00:00<?, ?it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CgJuPbRfDtS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}